# ğŸš€ ç•™å­¦ç”³è¯·AIå’¨è¯¢ç³»ç»Ÿéƒ¨ç½²æŒ‡å—

## ğŸ“‹ ç³»ç»Ÿæ¦‚è§ˆ

æœ¬ç³»ç»Ÿæ˜¯ä¸€ä¸ªåŸºäºLLMçš„æ™ºèƒ½ç•™å­¦ç”³è¯·å’¨è¯¢å¹³å°ï¼ŒåŒ…å«èƒŒæ™¯åˆ†æã€å­¦æ ¡æ¨èã€ç”³è¯·ç­–ç•¥åˆ¶å®šå’Œå®æ—¶æ™ºèƒ½å¯¹è¯åŠŸèƒ½ã€‚

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             å‰ç«¯å±‚                   â”‚
â”‚  React + WebSocket + å®æ—¶èŠå¤©ç•Œé¢     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚             APIç½‘å…³å±‚                â”‚
â”‚     FastAPI + JWTè®¤è¯ + è·¯ç”±ç®¡ç†      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚            AIæœåŠ¡å±‚                  â”‚
â”‚  OpenAI API + æç¤ºå·¥ç¨‹ + ç»“æœè§£æ     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚           ä¸šåŠ¡é€»è¾‘å±‚                 â”‚
â”‚ èƒŒæ™¯åˆ†æ + å­¦æ ¡æ¨è + ç­–ç•¥ç”Ÿæˆ + èŠå¤©  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚            æ•°æ®å±‚                    â”‚
â”‚ PostgreSQL + Redis + å‘é‡æ•°æ®åº“       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

### åç«¯æŠ€æœ¯æ ˆ
- **æ¡†æ¶**: FastAPI 0.104+
- **æ•°æ®åº“**: PostgreSQL 15+ (ä¸»æ•°æ®åº“)
- **ç¼“å­˜**: Redis 7+ (ä¼šè¯ç¼“å­˜)
- **å‘é‡æ•°æ®åº“**: pgvector (çŸ¥è¯†åº“æ£€ç´¢)
- **AIæœåŠ¡**: OpenAI GPT-4, Anthropic Claude-3
- **è®¤è¯**: JWT + bcrypt
- **éƒ¨ç½²**: Docker + Kubernetes

### å‰ç«¯æŠ€æœ¯æ ˆ
- **æ¡†æ¶**: React 18+ + TypeScript
- **çŠ¶æ€ç®¡ç†**: Zustand / Redux Toolkit
- **UIç»„ä»¶**: Tailwind CSS + HeadlessUI
- **å®æ—¶é€šä¿¡**: WebSocket / Socket.IO
- **æ„å»ºå·¥å…·**: Vite / Next.js

## ğŸ“¦ å®‰è£…éƒ¨ç½²

### 1. ç¯å¢ƒå‡†å¤‡

#### ç³»ç»Ÿè¦æ±‚
- Python 3.9+
- Node.js 16+
- PostgreSQL 15+
- Redis 7+
- Docker (å¯é€‰)

#### ä¾èµ–å®‰è£…
```bash
# å…‹éš†é¡¹ç›®
git clone <repository-url>
cd backend

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ– venv\Scripts\activate  # Windows

# å®‰è£…Pythonä¾èµ–
pip install -r requirements.txt

# å®‰è£…é¢å¤–çš„AIå’¨è¯¢ä¾èµ–
pip install openai anthropic tiktoken numpy pandas scikit-learn
```

### 2. æ•°æ®åº“é…ç½®

#### PostgreSQLè®¾ç½®
```sql
-- åˆ›å»ºæ•°æ®åº“
CREATE DATABASE study_abroad_ai;

-- å®‰è£…pgvectoræ‰©å±• (ç”¨äºå‘é‡æœç´¢)
CREATE EXTENSION vector;

-- å¯¼å…¥AIå’¨è¯¢ç³»ç»Ÿè¡¨ç»“æ„
\i ai_consultation_schema.sql
```

#### ç¯å¢ƒå˜é‡é…ç½®
åˆ›å»º `.env` æ–‡ä»¶ï¼š
```env
# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql://username:password@localhost:5432/study_abroad_ai
REDIS_URL=redis://localhost:6379/0

# AIæœåŠ¡é…ç½®
OPENAI_API_KEY=sk-your-openai-api-key
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key
AI_MODEL_PRIMARY=gpt-4  # ä¸»è¦ä½¿ç”¨çš„æ¨¡å‹
AI_MODEL_FALLBACK=gpt-3.5-turbo  # å¤‡ç”¨æ¨¡å‹

# Supabaseé…ç½® (å¦‚æœä½¿ç”¨)
SUPABASE_URL=your-supabase-url
SUPABASE_ANON_KEY=your-supabase-anon-key
SUPABASE_SERVICE_KEY=your-supabase-service-key

# åº”ç”¨é…ç½®
APP_NAME=ç•™å­¦ç”³è¯·AIå’¨è¯¢ç³»ç»Ÿ
SECRET_KEY=your-super-secret-key
DEBUG=true
HOST=0.0.0.0
PORT=8001

# å®‰å…¨é…ç½®
JWT_SECRET_KEY=your-jwt-secret-key
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7

# æ–‡ä»¶å­˜å‚¨
UPLOAD_MAX_SIZE=10485760  # 10MB
UPLOAD_ALLOWED_EXTENSIONS=pdf,doc,docx,txt

# é™æµé…ç½®
RATE_LIMIT_PER_MINUTE=60
AI_REQUESTS_PER_DAY=100
```

### 3. APIé›†æˆé…ç½®

#### åˆ›å»ºAIæœåŠ¡é…ç½®æ–‡ä»¶
```python
# app/core/ai_config.py
from typing import Dict, List
import os

class AIConfig:
    """AIæœåŠ¡é…ç½®"""
    
    # OpenAIé…ç½®
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    OPENAI_MODEL_PRIMARY = os.getenv("AI_MODEL_PRIMARY", "gpt-4")
    OPENAI_MODEL_FALLBACK = os.getenv("AI_MODEL_FALLBACK", "gpt-3.5-turbo")
    OPENAI_MAX_TOKENS = 2000
    OPENAI_TEMPERATURE = 0.7
    
    # Anthropicé…ç½®
    ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
    ANTHROPIC_MODEL = "claude-3-sonnet-20240229"
    
    # æˆæœ¬æ§åˆ¶
    MAX_TOKENS_PER_USER_PER_DAY = 50000
    MAX_REQUESTS_PER_USER_PER_HOUR = 20
    
    # æç¤ºè¯é…ç½®
    SYSTEM_PROMPTS = {
        "analysis": """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç•™å­¦ç”³è¯·é¡¾é—®ï¼Œæ‹¥æœ‰15å¹´çš„ç”³è¯·æŒ‡å¯¼ç»éªŒ...""",
        "recommendation": """ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ç•™å­¦é¡¾é—®ï¼Œç†Ÿæ‚‰å…¨çƒå„å¤§å­¦çš„å½•å–è¦æ±‚...""",
        "strategy": """ä½ æ˜¯ä¸€ä½ç•™å­¦ç”³è¯·ç­–ç•¥ä¸“å®¶ï¼Œæ“…é•¿åˆ¶å®šè¯¦ç»†çš„ç”³è¯·è®¡åˆ’...""",
        "chat": """ä½ æ˜¯ä¸€ä½äº²åˆ‡ã€ä¸“ä¸šçš„ç•™å­¦ç”³è¯·é¡¾é—®AIåŠ©æ‰‹ï¼Œåå­—å«"å°ç”³"..."""
    }
```

### 4. å¯åŠ¨æœåŠ¡

#### å¼€å‘ç¯å¢ƒå¯åŠ¨
```bash
# å¯åŠ¨Redis (å¦‚æœæ²¡æœ‰æœåŠ¡)
redis-server

# å¯åŠ¨PostgreSQL (å¦‚æœæ²¡æœ‰æœåŠ¡)
pg_ctl start

# å¯åŠ¨FastAPIåº”ç”¨
python start_new_app.py

# æˆ–ä½¿ç”¨uvicornç›´æ¥å¯åŠ¨
uvicorn app.main:app --host 0.0.0.0 --port 8001 --reload
```

#### éªŒè¯å¯åŠ¨
```bash
# æ£€æŸ¥APIå¥åº·çŠ¶æ€
curl http://localhost:8001/health

# æ£€æŸ¥APIæ–‡æ¡£
curl http://localhost:8001/docs
```

### 5. å‰ç«¯éƒ¨ç½²

#### Reactåº”ç”¨æ„å»º
```bash
cd frontend

# å®‰è£…ä¾èµ–
npm install

# å®‰è£…é¢å¤–ä¾èµ–
npm install @heroicons/react lucide-react axios socket.io-client

# åˆ›å»ºç¯å¢ƒé…ç½®
echo "VITE_API_BASE_URL=http://localhost:8001" > .env.local

# å¼€å‘æ¨¡å¼å¯åŠ¨
npm run dev

# ç”Ÿäº§æ„å»º
npm run build
```

## ğŸ”§ é…ç½®ä¼˜åŒ–

### 1. æ•°æ®åº“ä¼˜åŒ–

#### PostgreSQLæ€§èƒ½ä¼˜åŒ–
```sql
-- å¢åŠ è¿æ¥æ± å¤§å°
ALTER SYSTEM SET max_connections = 200;

-- ä¼˜åŒ–å†…å­˜è®¾ç½®
ALTER SYSTEM SET shared_buffers = '256MB';
ALTER SYSTEM SET work_mem = '4MB';

-- åˆ›å»ºå¿…è¦ç´¢å¼•
CREATE INDEX CONCURRENTLY idx_chat_messages_session_timestamp 
ON chat_messages(session_id, created_at);

CREATE INDEX CONCURRENTLY idx_consultation_sessions_user_activity 
ON consultation_sessions(user_id, last_activity);

-- è®¾ç½®è‡ªåŠ¨æ¸…ç†
ALTER TABLE chat_messages SET (autovacuum_vacuum_scale_factor = 0.1);
```

#### Redisé…ç½®ä¼˜åŒ–
```redis
# redis.conf
maxmemory 512mb
maxmemory-policy allkeys-lru
save 900 1
save 300 10
save 60 10000
```

### 2. AIæœåŠ¡ä¼˜åŒ–

#### æˆæœ¬æ§åˆ¶ç­–ç•¥
```python
# app/services/ai_cost_control.py
class AICostController:
    """AIæˆæœ¬æ§åˆ¶å™¨"""
    
    def __init__(self):
        self.daily_limits = {
            "free_user": 10,      # å…è´¹ç”¨æˆ·æ¯æ—¥10æ¬¡
            "premium_user": 100,   # ä»˜è´¹ç”¨æˆ·æ¯æ—¥100æ¬¡
            "enterprise": 1000     # ä¼ä¸šç”¨æˆ·æ¯æ—¥1000æ¬¡
        }
    
    async def check_usage_limit(self, user_id: int, user_tier: str) -> bool:
        """æ£€æŸ¥ç”¨æˆ·ä½¿ç”¨é™åˆ¶"""
        today_usage = await self.get_today_usage(user_id)
        limit = self.daily_limits.get(user_tier, 10)
        return today_usage < limit
    
    async def log_ai_usage(self, user_id: int, model: str, 
                          tokens_used: int, cost: float):
        """è®°å½•AIä½¿ç”¨æƒ…å†µ"""
        # å®ç°ä½¿ç”¨è®°å½•é€»è¾‘
        pass
```

#### æ™ºèƒ½æ¨¡å‹é€‰æ‹©
```python
# app/services/model_selector.py
class ModelSelector:
    """æ™ºèƒ½æ¨¡å‹é€‰æ‹©å™¨"""
    
    def select_model(self, task_type: str, user_tier: str, 
                    complexity: str = "medium") -> str:
        """æ ¹æ®ä»»åŠ¡ç±»å‹å’Œç”¨æˆ·ç­‰çº§é€‰æ‹©æœ€é€‚åˆçš„æ¨¡å‹"""
        
        if user_tier == "enterprise" or complexity == "high":
            return "gpt-4"
        elif task_type in ["analysis", "recommendation"]:
            return "gpt-4"  # æ ¸å¿ƒåŠŸèƒ½ä½¿ç”¨é«˜è´¨é‡æ¨¡å‹
        else:
            return "gpt-3.5-turbo"  # æ—¥å¸¸å¯¹è¯ä½¿ç”¨ç»æµæ¨¡å‹
```

### 3. ç¼“å­˜ç­–ç•¥

#### Redisç¼“å­˜é…ç½®
```python
# app/core/cache.py
import redis
import json
from typing import Any, Optional

class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self):
        self.redis_client = redis.from_url(os.getenv("REDIS_URL"))
        self.default_ttl = 3600  # 1å°æ—¶
    
    async def cache_analysis_result(self, profile_hash: str, 
                                  analysis: dict, ttl: int = 86400):
        """ç¼“å­˜åˆ†æç»“æœ (24å°æ—¶)"""
        key = f"analysis:{profile_hash}"
        await self.redis_client.setex(
            key, ttl, json.dumps(analysis)
        )
    
    async def cache_school_recommendations(self, profile_hash: str, 
                                         recommendations: list, ttl: int = 43200):
        """ç¼“å­˜å­¦æ ¡æ¨è (12å°æ—¶)"""
        key = f"recommendations:{profile_hash}"
        await self.redis_client.setex(
            key, ttl, json.dumps(recommendations)
        )
```

## ğŸ³ Dockeréƒ¨ç½²

### 1. Dockerfileé…ç½®

#### åç«¯Dockerfile
```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1

# æš´éœ²ç«¯å£
EXPOSE 8001

# å¯åŠ¨å‘½ä»¤
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8001"]
```

#### å‰ç«¯Dockerfile
```dockerfile
# frontend/Dockerfile
FROM node:18-alpine

WORKDIR /app

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY package*.json ./
RUN npm ci --only=production

# å¤åˆ¶æºä»£ç 
COPY . .

# æ„å»ºåº”ç”¨
RUN npm run build

# ä½¿ç”¨nginxæä¾›é™æ€æ–‡ä»¶
FROM nginx:alpine
COPY --from=0 /app/dist /usr/share/nginx/html
COPY nginx.conf /etc/nginx/nginx.conf

EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```

### 2. Docker Composeé…ç½®

```yaml
# docker-compose.yml
version: '3.8'

services:
  db:
    image: pgvector/pgvector:pg15
    environment:
      POSTGRES_DB: study_abroad_ai
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./ai_consultation_schema.sql:/docker-entrypoint-initdb.d/schema.sql
    ports:
      - "5432:5432"

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"

  backend:
    build: .
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/study_abroad_ai
      - REDIS_URL=redis://redis:6379/0
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    depends_on:
      - db
      - redis
    ports:
      - "8001:8001"
    volumes:
      - ./uploads:/app/uploads

  frontend:
    build: ./frontend
    ports:
      - "3000:80"
    depends_on:
      - backend

volumes:
  postgres_data:
  redis_data:
```

### 3. éƒ¨ç½²å‘½ä»¤

```bash
# æ„å»ºå¹¶å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up --build -d

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f backend

# åœæ­¢æœåŠ¡
docker-compose down
```

## ğŸ” å®‰å…¨é…ç½®

### 1. APIå®‰å…¨

#### é™æµé…ç½®
```python
# app/middleware/rate_limit.py
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

limiter = Limiter(key_func=get_remote_address)

# åº”ç”¨çº§é™æµ
@limiter.limit("100/minute")
async def api_endpoint():
    pass

# AIè¯·æ±‚ç‰¹æ®Šé™æµ
@limiter.limit("10/minute")
async def ai_consultation_endpoint():
    pass
```

#### è¾“å…¥éªŒè¯
```python
# app/middleware/input_validation.py
from pydantic import validator
import bleach

class SecureInput(BaseModel):
    content: str
    
    @validator('content')
    def sanitize_content(cls, v):
        # æ¸…ç†HTMLæ ‡ç­¾
        cleaned = bleach.clean(v, tags=[], strip=True)
        # é™åˆ¶é•¿åº¦
        if len(cleaned) > 5000:
            raise ValueError('è¾“å…¥å†…å®¹è¿‡é•¿')
        return cleaned
```

### 2. æ•°æ®å®‰å…¨

#### æ•æ„Ÿä¿¡æ¯åŠ å¯†
```python
# app/core/encryption.py
from cryptography.fernet import Fernet
import os

class DataEncryption:
    """æ•°æ®åŠ å¯†å·¥å…·"""
    
    def __init__(self):
        self.key = os.getenv("ENCRYPTION_KEY").encode()
        self.cipher = Fernet(self.key)
    
    def encrypt_sensitive_data(self, data: str) -> str:
        """åŠ å¯†æ•æ„Ÿæ•°æ®"""
        return self.cipher.encrypt(data.encode()).decode()
    
    def decrypt_sensitive_data(self, encrypted_data: str) -> str:
        """è§£å¯†æ•æ„Ÿæ•°æ®"""
        return self.cipher.decrypt(encrypted_data.encode()).decode()
```

## ğŸ“Š ç›‘æ§é…ç½®

### 1. åº”ç”¨ç›‘æ§

#### Prometheusç›‘æ§
```python
# app/middleware/metrics.py
from prometheus_client import Counter, Histogram, generate_latest

# å®šä¹‰æŒ‡æ ‡
REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests')
REQUEST_DURATION = Histogram('http_request_duration_seconds', 'HTTP request duration')
AI_REQUESTS = Counter('ai_requests_total', 'Total AI requests', ['model', 'operation'])

@app.middleware("http")
async def add_prometheus_middleware(request: Request, call_next):
    start_time = time.time()
    response = await call_next(request)
    
    REQUEST_COUNT.inc()
    REQUEST_DURATION.observe(time.time() - start_time)
    
    return response
```

#### å¥åº·æ£€æŸ¥ç«¯ç‚¹
```python
# app/api/health.py
@router.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    checks = {
        "database": await check_database_connection(),
        "redis": await check_redis_connection(),
        "ai_service": await check_ai_service(),
        "disk_space": check_disk_space()
    }
    
    is_healthy = all(checks.values())
    status_code = 200 if is_healthy else 503
    
    return JSONResponse(
        content={"status": "healthy" if is_healthy else "unhealthy", "checks": checks},
        status_code=status_code
    )
```

### 2. æ—¥å¿—é…ç½®

#### ç»“æ„åŒ–æ—¥å¿—
```python
# app/core/logging.py
import structlog
import logging

def setup_logging():
    """é…ç½®ç»“æ„åŒ–æ—¥å¿—"""
    structlog.configure(
        processors=[
            structlog.stdlib.filter_by_level,
            structlog.stdlib.add_logger_name,
            structlog.stdlib.add_log_level,
            structlog.stdlib.PositionalArgumentsFormatter(),
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.StackInfoRenderer(),
            structlog.processors.format_exc_info,
            structlog.processors.UnicodeDecoder(),
            structlog.processors.JSONRenderer()
        ],
        context_class=dict,
        logger_factory=structlog.stdlib.LoggerFactory(),
        wrapper_class=structlog.stdlib.BoundLogger,
        cache_logger_on_first_use=True,
    )
```

## ğŸš€ ç”Ÿäº§éƒ¨ç½²

### 1. Kuberneteséƒ¨ç½²

#### éƒ¨ç½²é…ç½®
```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-consultation-backend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ai-consultation-backend
  template:
    metadata:
      labels:
        app: ai-consultation-backend
    spec:
      containers:
      - name: backend
        image: your-registry/ai-consultation:latest
        ports:
        - containerPort: 8001
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: url
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: ai-secret
              key: openai-key
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 1000m
            memory: 2Gi
```

### 2. CI/CDæµæ°´çº¿

#### GitHub Actionsé…ç½®
```yaml
# .github/workflows/deploy.yml
name: Deploy AI Consultation System

on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install pytest
    - name: Run tests
      run: pytest tests/

  deploy:
    needs: test
    runs-on: ubuntu-latest
    steps:
    - name: Deploy to production
      run: |
        # éƒ¨ç½²è„šæœ¬
        echo "Deploying to production..."
```

## ğŸ“ˆ æ‰©å±•æ€§è€ƒè™‘

### 1. å¾®æœåŠ¡æ¶æ„

```
AIå’¨è¯¢ç³»ç»Ÿ â†’ æ‹†åˆ†ä¸ºï¼š
â”œâ”€â”€ ç”¨æˆ·è®¤è¯æœåŠ¡ (auth-service)
â”œâ”€â”€ èƒŒæ™¯åˆ†ææœåŠ¡ (analysis-service)  
â”œâ”€â”€ å­¦æ ¡æ¨èæœåŠ¡ (recommendation-service)
â”œâ”€â”€ èŠå¤©æœåŠ¡ (chat-service)
â”œâ”€â”€ é€šçŸ¥æœåŠ¡ (notification-service)
â””â”€â”€ æ–‡ä»¶æœåŠ¡ (file-service)
```

### 2. è´Ÿè½½å‡è¡¡

```nginx
# nginx.conf
upstream backend {
    server backend-1:8001;
    server backend-2:8001;
    server backend-3:8001;
}

server {
    listen 80;
    location /api/ {
        proxy_pass http://backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

è¿™ä¸ªéƒ¨ç½²æŒ‡å—ä¸ºä½ çš„AIå’¨è¯¢ç³»ç»Ÿæä¾›äº†å®Œæ•´çš„ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æ–¹æ¡ˆã€‚ä½ å¯ä»¥æ ¹æ®å®é™…éœ€æ±‚é€‰æ‹©åˆé€‚çš„éƒ¨ç½²æ–¹å¼ï¼Œä»ç®€å•çš„å•æœºéƒ¨ç½²åˆ°å¤æ‚çš„Kubernetesé›†ç¾¤éƒ½æœ‰æ¶µç›–ã€‚
